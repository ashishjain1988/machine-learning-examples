{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#https://www.analyticsvidhya.com/blog/2018/05/essentials-of-deep-learning-trudging-into-unsupervised-deep-learning/\n",
    "#https://www.dlology.com/blog/how-to-do-unsupervised-clustering-with-keras/\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.datasets import mnist\n",
    "import os\n",
    "import keras\n",
    "#import metrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "\n",
    "from time import time\n",
    "\n",
    "from keras import callbacks\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense, Input\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.engine.topology import Layer, InputSpec\n",
    "\n",
    "from scipy.misc import imread\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, normalized_mutual_info_score\n",
    "\n",
    "import nets\n",
    "#from evolutron.motifs import motif_extraction\n",
    "from evolutron.templates import callback_templates as cb\n",
    "from evolutron.extra_metrics import mean_cat_acc\n",
    "from evolutron.extra_objectives import masked_mse, multiclass_categorical_crossentropy\n",
    "from evolutron.tools import Handle, load_dataset, load_random_aa_seqs, preprocess_dataset\n",
    "from keras import backend\n",
    "\n",
    "from keras.layers import Activation, BatchNormalization, Convolution1D, Dense, Flatten, GlobalMaxPooling1D, Input,MaxPooling1D, Reshape, Conv2DTranspose, UpSampling1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/efs/home/ctg3039/CoMET-master/evolutron/tools/io_tools.py:108: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  ~raw_data[code_key].isin(code_vc[code_vc == 1].index.tolist())]\n"
     ]
    }
   ],
   "source": [
    "x_data, y_data = load_dataset(\"example/sprot_dna_tf_pfam.tsv\", codes=True, code_key=\"fam\")\n",
    "#x_data, y_data = preprocess_dataset(x_data, y_data, padded=not False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MATQADLMELDMAMEPDRKAAVSHWQQQSYLDSGIHSGATTTAPSLSGKGNPEEEDVDTSQVLYEWEQGFSQSFTQEQVADIDGQYAMTRAQRVRAAMFPETLDEGMQIPSTQFDAAHPTNVQRLAEPSQMLKHAVVNLINYQDDAELATRAIPELTKLLNDEDQVVVNKAAVMVHQLSKKEASRHAIMRSPQMVSAIVRTMQNTNDVETARCTAGTLHNLSHHREGLLAIFKSGGIPALVKMLGSPVDSVLFYAITTLHNLLLHQEGAKMAVRLAGGLQKMVALLNKTNVKFLAITTDCLQILAYGNQESKLIILASGGPQALVNIMRTYTYEKLLWTTSRVLKVLSVCSSNKPAIVEAGGMQALGLHLTDPSQRLVQNCLWTLRNLSDAATKQEGMEGLLGTLVQLLGSDDINVVTCAAGILSNLTCNNYKNKMMVCQVGGIEALVRTVLRAGDREDITEPAICALRHLTSRHQEAEMAQNAVRLHYGLPVVVKLLHPPSHWPLIKATVGLIRNLALCPANHAPLREQGAIPRLVQLLVRAHQDTQRRTSMGGTQQQFVEGVRMEEIVEGCTGALHILARDVHNRIVIRGLNTIPLFVQLLYSPIENIQRVAAGVLCELAQDKEAAEAIEAEGATAPLTELLHSRNEGVATYAAAVLFRMSEDKPQDYKKRLSVELTSSLFRTEPMAWNETADLGLDIGAQGEALGYRQDDPSYRSFHSGGYGQDALGMDPMMEHEMGGHHPGADYPVDGLPDLGHAQDLMDGLPPGDSNQLAWFDTDL'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "train_x = np.concatenate((x_train, x_test))\n",
    "train_y = np.concatenate((y_train, y_test))\n",
    "train_x = train_x.reshape((train_x.shape[0], -1))\n",
    "train_x = np.divide(train_x, 255.)\n",
    "\n",
    "split_size = int(train_x.shape[0]*0.7)\n",
    "train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "train_y, val_y = train_y[:split_size], train_y[split_size:]\n",
    "\n",
    "# this is our input placeholder\n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = Dense(500, activation='relu')(input_img)\n",
    "encoded = Dense(500, activation='relu')(encoded)\n",
    "encoded = Dense(2000, activation='relu')(encoded)\n",
    "encoded = Dense(10, activation='sigmoid')(encoded)\n",
    "\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = Dense(2000, activation='relu')(encoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(500, activation='relu')(decoded)\n",
    "decoded = Dense(784)(decoded)\n",
    "\n",
    "# this model maps an input to its reconstruction\n",
    "autoencoder = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1294"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "raw_data = pd.read_csv('example/sprot_dna_tf_pfam.tsv', sep=\"\\t\", header='infer')\n",
    "raw_data.columns = raw_data.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "length = [len(x) for x in raw_data.sequence]\n",
    "t=[]\n",
    "#length = [x for x in raw_data.sequence if len(x)<=300 and len(x)>=275]\n",
    "with open('example/sprot_dna_tf_pfam_275to325.tsv', 'w') as handle:\n",
    "    writer = csv.writer(handle, delimiter='\\t')\n",
    "    writer.writerow([\"Sequence\"])\n",
    "    for x in raw_data.sequence:\n",
    "        if len(x)<=325 and len(x)>=275:\n",
    "            #print(len(x))\n",
    "            t.append(x)\n",
    "            writer.writerow([x])\n",
    "len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(length, bins='auto',density=True, facecolor='g')\n",
    "plt.xlabel('Seqeunce length')\n",
    "plt.gca().set_xlim(right=500)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Sequence length distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 11036\n",
      "The input data format(?, 1439, 20)\n",
      "The Conv1 data format(?, 1439, 400)\n",
      "The Conv2 data format(?, 1439, 400)\n",
      "The Pool data format(?, 400)\n",
      "The Dense data format(?, 400)\n",
      "(400,)\n",
      "The DeDense data format(?, 400)\n",
      "The Reshape data format(?, 1, 400)\n",
      "The UpSamplingCov2 data format(?, 1439, 400)\n",
      "The DeCov2 data format(?, 1439, 400)\n",
      "(?, 1439, 20)\n"
     ]
    }
   ],
   "source": [
    "###CNN Autoencoder\n",
    "x_data, _ = load_dataset(\"example/sprot_dna_tf_pfam.tsv\")\n",
    "x_data = preprocess_dataset(x_data, padded=not False)\n",
    "train_x = x_data\n",
    "#split_size = int(train_x.shape[0]*0.7)\n",
    "#train_x, val_x = train_x[:split_size], train_x[split_size:]\n",
    "#print(x_data[0].shape)\n",
    "input_shape = x_data[0].shape\n",
    "\n",
    "input_seq = Input(shape=input_shape, name='aa_seq')\n",
    "print('The input data format{0}'.format(input_seq.get_shape()))\n",
    "#x = Conv2D(filters[0], 5, strides=2, padding='same', activation='relu', name='conv1', input_shape=input_shape)(input_img)\n",
    "x = Convolution1D(filters=400,kernel_size=50,strides=1,padding='same',use_bias=False,kernel_initializer='glorot_uniform',activation='relu',name='Conv1')(input_seq)\n",
    "print(\"The Conv1 data format{0}\".format(x.get_shape()))\n",
    "x = Convolution1D(filters=400,kernel_size=100,strides=1,padding='same',use_bias=False,kernel_initializer='glorot_uniform',activation='relu',name='Conv2')(x)\n",
    "print(\"The Conv2 data format{0}\".format(x.get_shape()))\n",
    "#conv2DShape = x.get_shape[1]\n",
    "#x = Conv2D(filters[2], 3, strides=2, padding=pad3, activation='relu', name='conv3')(x)\n",
    "shape_before_flattening = K.int_shape(x)\n",
    "pool = GlobalMaxPooling1D()(x)#Give the size of the filter\n",
    "print(\"The Pool data format{0}\".format(pool.get_shape()))\n",
    "#x = Flatten()(x)\n",
    "#x = Dense(units=filters[2], name='Dense1')(pool)\n",
    "encoded = Dense(units=400, activation='sigmoid',name='embedding')(pool)\n",
    "print(\"The Dense data format{0}\".format(encoded.get_shape()))\n",
    "#x = Dense(units=filters[3], activation='relu')(encoded)\n",
    "\n",
    "print((shape_before_flattening[2:]))\n",
    "# Decoder\n",
    "x = Dense(np.prod(shape_before_flattening[2:]),activation='relu')(encoded)\n",
    "print(\"The DeDense data format{0}\".format(x.get_shape()))\n",
    "#x = Reshape((1,400))(x)\n",
    "x = Reshape((1,np.prod(shape_before_flattening[2:])))(x)\n",
    "print(\"The Reshape data format{0}\".format(x.get_shape()))\n",
    "x = UpSampling1D(1439)(x)\n",
    "print(\"The UpSamplingCov2 data format{0}\".format(x.get_shape()))\n",
    "#print(\"The UpSamplingCov2 data format{0}\".format(x.get_shape()))\n",
    "x = Convolution1D(filters=400,kernel_size=50, activation='relu', padding='same')(x)\n",
    "print(\"The DeCov2 data format{0}\".format(x.get_shape()))\n",
    "#x = UpSampling1D()(x)\n",
    "#x = Convolution1D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "#x = Convolution1D(16, (3, 3), activation='relu')(x)\n",
    "#x = UpSampling2D((1))(x)\n",
    "decoded = Convolution1D(filters=20,kernel_size=50, activation='softmax', padding='same')(x)\n",
    "print(decoded.get_shape())\n",
    "    \n",
    "autoencoder = Model(inputs=input_seq, outputs=decoded, name='AE')\n",
    "encoder = Model(inputs=input_seq, outputs=encoded, name='encoder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'div:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#t = train_x.reshape((train_x.shape[0], -1))\n",
    "#t.shape\n",
    "#mean_cat_acc(x_data[0],x_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "aa_seq (InputLayer)          (None, 1439, 20)          0         \n",
      "_________________________________________________________________\n",
      "Conv1 (Conv1D)               (None, 1439, 400)         400000    \n",
      "_________________________________________________________________\n",
      "Conv2 (Conv1D)               (None, 1439, 400)         16000000  \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Dense)            (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 1, 400)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1 (None, 1439, 400)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1439, 400)         8000400   \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1439, 20)          400020    \n",
      "=================================================================\n",
      "Total params: 25,121,220\n",
      "Trainable params: 25,121,220\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='nadam', loss=[multiclass_categorical_crossentropy],metrics=[mean_cat_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8828 samples, validate on 2208 samples\n",
      "Epoch 1/10\n",
      "8828/8828 [==============================] - 88s 10ms/step - loss: 15.7286 - mean_cat_acc: 0.0925 - val_loss: 15.7308 - val_mean_cat_acc: 0.0876\n",
      "Epoch 2/10\n",
      "8828/8828 [==============================] - 79s 9ms/step - loss: 15.7275 - mean_cat_acc: 0.0930 - val_loss: 15.7308 - val_mean_cat_acc: 0.0876\n",
      "Epoch 3/10\n",
      "8828/8828 [==============================] - 79s 9ms/step - loss: 15.7275 - mean_cat_acc: 0.0929 - val_loss: 15.7308 - val_mean_cat_acc: 0.0876\n",
      "Epoch 4/10\n",
      "8828/8828 [==============================] - 79s 9ms/step - loss: 15.7275 - mean_cat_acc: 0.0929 - val_loss: 15.7308 - val_mean_cat_acc: 0.0876\n",
      "Epoch 5/10\n",
      "8828/8828 [==============================] - 79s 9ms/step - loss: 15.7275 - mean_cat_acc: 0.0930 - val_loss: 15.7308 - val_mean_cat_acc: 0.0876\n",
      "Epoch 6/10\n",
      "8828/8828 [==============================] - 79s 9ms/step - loss: 15.7275 - mean_cat_acc: 0.0929 - val_loss: 15.7308 - val_mean_cat_acc: 0.0876\n",
      "Epoch 7/10\n",
      "8828/8828 [==============================] - 79s 9ms/step - loss: 15.7275 - mean_cat_acc: 0.0930 - val_loss: 15.7308 - val_mean_cat_acc: 0.0876\n",
      "Epoch 8/10\n",
      "8828/8828 [==============================] - 79s 9ms/step - loss: 15.7275 - mean_cat_acc: 0.0929 - val_loss: 15.7308 - val_mean_cat_acc: 0.0876\n",
      "Epoch 9/10\n",
      "8828/8828 [==============================] - 79s 9ms/step - loss: 15.7275 - mean_cat_acc: 0.0930 - val_loss: 15.7308 - val_mean_cat_acc: 0.0876\n",
      "Epoch 10/10\n",
      "8828/8828 [==============================] - 79s 9ms/step - loss: 15.7275 - mean_cat_acc: 0.0930 - val_loss: 15.7308 - val_mean_cat_acc: 0.0876\n"
     ]
    }
   ],
   "source": [
    "train_history = autoencoder.fit(train_x, train_x, epochs=10, batch_size=50, validation_split=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/sklearn/metrics/cluster/supervised.py:844: FutureWarning: The behavior of NMI will change in version 0.22. To match the behavior of 'v_measure_score', NMI will use average_method='arithmetic' by default.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6795889475785513"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km = KMeans(n_jobs=-1, n_clusters=10, n_init=20)\n",
    "pred_auto_train = encoder.predict(train_x)\n",
    "pred_auto = encoder.predict(val_x)\n",
    "km.fit(pred_auto_train)\n",
    "pred = km.predict(pred_auto)\n",
    "normalized_mutual_info_score(val_y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21000, 10)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_auto.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Keras implementation for Deep Embedded Clustering (DEC) algorithm:\n",
    "\n",
    "Original Author:\n",
    "    Xifeng Guo. 2017.1.30\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def autoencoder(dims, act='relu', init='glorot_uniform'):\n",
    "    \"\"\"\n",
    "    Fully connected auto-encoder model, symmetric.\n",
    "    Arguments:\n",
    "        dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n",
    "            The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n",
    "        act: activation, not applied to Input, Hidden and Output layers\n",
    "    return:\n",
    "        (ae_model, encoder_model), Model of autoencoder and model of encoder\n",
    "    \"\"\"\n",
    "    n_stacks = len(dims) - 1\n",
    "    # input\n",
    "    x = Input(shape=(dims[0],), name='input')\n",
    "    h = x\n",
    "\n",
    "    # internal layers in encoder\n",
    "    for i in range(n_stacks-1):\n",
    "        h = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(h)\n",
    "\n",
    "    # hidden layer\n",
    "    h = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(h)  # hidden layer, features are extracted from here\n",
    "\n",
    "    y = h\n",
    "    # internal layers in decoder\n",
    "    for i in range(n_stacks-1, 0, -1):\n",
    "        y = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(y)\n",
    "\n",
    "    # output\n",
    "    y = Dense(dims[0], kernel_initializer=init, name='decoder_0')(y)\n",
    "\n",
    "    return Model(inputs=x, outputs=y, name='AE'), Model(inputs=x, outputs=h, name='encoder')\n",
    "\n",
    "def autoencoderConv2D_1(input_shape=(1590, 20), filters=[400,800,400,400]):\n",
    "    \n",
    "    input_seq = Input(shape=input_shape)\n",
    "    \n",
    "    #if input_shape[0] % 8 == 0:\n",
    "    #    pad3 = 'same'\n",
    "    #else:\n",
    "    #    pad3 = 'valid'\n",
    "    \n",
    "    #x = Conv2D(filters[0], 5, strides=2, padding='same', activation='relu', name='conv1', input_shape=input_shape)(input_img)\n",
    "    x = Convolution1D(filters=filters[0],kernel_size=50,strides=1,padding='same',use_bias=False,kernel_initializer='glorot_uniform',activation='relu',name='Conv1')(input_seq)\n",
    "    x = Convolution1D(filters=filters[1],kernel_size=50,strides=1,padding='same',use_bias=False,kernel_initializer='glorot_uniform',activation='relu',name='Conv2')(x)\n",
    "\n",
    "    #x = Conv2D(filters[2], 3, strides=2, padding=pad3, activation='relu', name='conv3')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=filters[2], name='Dense1')(x)\n",
    "    encoded = Dense(units=filters[3], name='embedding')(x)\n",
    "    x = Dense(units=filters[3], activation='relu')(encoded)\n",
    "    x = Dense(units=filters[2], activation='relu')(x)\n",
    "    \n",
    "    x = Reshape((1,400))(x)\n",
    "    \n",
    "    #Maybe use the UpSampling1D and Conv1D\n",
    "    \n",
    "    #x = Reshape((-1,1,20))(x)\n",
    "    \n",
    "    #x = Conv2DTranspose(filters[1], 3, strides=2, padding=pad3, activation='relu', name='deconv3')(x)\n",
    "\n",
    "    #x = Conv2DTranspose(filters=20, kernel_size = (50,1),strides=1, padding='same', activation='relu', name='deconv2')(x)\n",
    "\n",
    "    #decoded = Conv2DTranspose(input_shape[1], kernel_size = (50,1), strides=1, padding='same', name='deconv1')(x)\n",
    "    \n",
    "    return Model(inputs=input_seq, outputs=decoded, name='AE'), Model(inputs=input_seq, outputs=encoded, name='encoder')\n",
    "\n",
    "class ClusteringLayer(Layer):\n",
    "    \"\"\"\n",
    "    Clustering layer converts input sample (feature) to soft label, i.e. a vector that represents the probability of the\n",
    "    sample belonging to each cluster. The probability is calculated with student's t-distribution.\n",
    "\n",
    "    # Example\n",
    "    ```\n",
    "        model.add(ClusteringLayer(n_clusters=10))\n",
    "    ```\n",
    "    # Arguments\n",
    "        n_clusters: number of clusters.\n",
    "        weights: list of Numpy array with shape `(n_clusters, n_features)` witch represents the initial cluster centers.\n",
    "        alpha: parameter in Student's t-distribution. Default to 1.0.\n",
    "    # Input shape\n",
    "        2D tensor with shape: `(n_samples, n_features)`.\n",
    "    # Output shape\n",
    "        2D tensor with shape: `(n_samples, n_clusters)`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight((self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        \"\"\" student t-distribution, as same as used in t-SNE algorithm.\n",
    "                 q_ij = 1/(1+dist(x_i, u_j)^2), then normalize it.\n",
    "        Arguments:\n",
    "            inputs: the variable containing data, shape=(n_samples, n_features)\n",
    "        Return:\n",
    "            q: student's t-distribution, or soft labels for each sample. shape=(n_samples, n_clusters)\n",
    "        \"\"\"\n",
    "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1))\n",
    "        return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "class DEC(object):\n",
    "    def __init__(self,\n",
    "                 dims,\n",
    "                 n_clusters=10,\n",
    "                 alpha=1.0,\n",
    "                 init='glorot_uniform'):\n",
    "\n",
    "        super(DEC, self).__init__()\n",
    "\n",
    "        self.dims = dims\n",
    "        self.input_dim = dims[0]\n",
    "        self.n_stacks = len(self.dims) - 1\n",
    "\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.autoencoder, self.encoder = autoencoder(self.dims, init=init)\n",
    "        #print(self.input_dim)\n",
    "        #self.autoencoder, self.encoder = autoencoderConv2D_1(self.input_dim)\n",
    "\n",
    "        # prepare DEC model\n",
    "        clustering_layer = ClusteringLayer(self.n_clusters, name='clustering')(self.encoder.output)\n",
    "        self.model = Model(inputs=self.encoder.input, outputs=clustering_layer)\n",
    "\n",
    "    def pretrain(self, x, y=None, optimizer='adam', epochs=200, batch_size=256, save_dir='results/temp'):\n",
    "        print('...Pretraining...')\n",
    "        self.autoencoder.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "        csv_logger = callbacks.CSVLogger(save_dir + '/pretrain_log.csv')\n",
    "        cb = [csv_logger]\n",
    "        if y is not None:\n",
    "            class PrintACC(callbacks.Callback):\n",
    "                def __init__(self, x, y):\n",
    "                    self.x = x\n",
    "                    self.y = y\n",
    "                    super(PrintACC, self).__init__()\n",
    "\n",
    "                def on_epoch_end(self, epoch, logs=None):\n",
    "                    if epoch % int(epochs/10) != 0:\n",
    "                        return\n",
    "                    feature_model = Model(self.model.input,\n",
    "                                          self.model.get_layer(\n",
    "                                              'encoder_%d' % (int(len(self.model.layers) / 2) - 1)).output)\n",
    "                    features = feature_model.predict(self.x)\n",
    "                    km = KMeans(n_clusters=len(np.unique(self.y)), n_init=20, n_jobs=4)\n",
    "                    y_pred = km.fit_predict(features)\n",
    "                    # print()\n",
    "                    #print(' '*8 + '|==>  acc: %.4f,  nmi: %.4f  <==|'\n",
    "                    #      % (metrics.acc(self.y, y_pred), metrics.nmi(self.y, y_pred)))\n",
    "                    print(' '*8 + '|==>  acc: %.4f,  nmi: %.4f  <==|'\n",
    "                          % (accuracy_score(self.y, y_pred), normalized_mutual_info_score(self.y, y_pred)))\n",
    "                    \n",
    "\n",
    "            cb.append(PrintACC(x, y))\n",
    "\n",
    "        # begin pretraining\n",
    "        t0 = time()\n",
    "        self.autoencoder.fit(x, x, batch_size=batch_size, epochs=epochs, callbacks=cb)\n",
    "        print('Pretraining time: ', time() - t0)\n",
    "        self.autoencoder.save_weights(save_dir + '/ae_weights.h5')\n",
    "        print('Pretrained weights are saved to %s/ae_weights.h5' % save_dir)\n",
    "        self.pretrained = True\n",
    "\n",
    "    def load_weights(self, weights):  # load weights of DEC model\n",
    "        self.model.load_weights(weights)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        return self.encoder.predict(x)\n",
    "\n",
    "    def predict(self, x):  # predict cluster labels using the output of clustering layer\n",
    "        q = self.model.predict(x, verbose=0)\n",
    "        return q.argmax(1)\n",
    "\n",
    "    @staticmethod\n",
    "    def target_distribution(q):\n",
    "        weight = q ** 2 / q.sum(0)\n",
    "        return (weight.T / weight.sum(1)).T\n",
    "\n",
    "    def compile(self, optimizer='sgd', loss='kld'):\n",
    "        self.model.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "    def fit(self, x, y=None, maxiter=2e4, batch_size=256, tol=1e-3,\n",
    "            update_interval=140, save_dir='./results/temp'):\n",
    "\n",
    "        print('Update interval', update_interval)\n",
    "        save_interval = x.shape[0] / batch_size * 5  # 5 epochs\n",
    "        print('Save interval', save_interval)\n",
    "\n",
    "        # Step 1: initialize cluster centers using k-means\n",
    "        t1 = time()\n",
    "        print('Initializing cluster centers with k-means.')\n",
    "        kmeans = KMeans(n_clusters=self.n_clusters, n_init=20)\n",
    "        y_pred = kmeans.fit_predict(self.encoder.predict(x))\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        self.model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "\n",
    "        # Step 2: deep clustering\n",
    "        # logging file\n",
    "        import csv\n",
    "        logfile = open(save_dir + '/dec_log.csv', 'w')\n",
    "        logwriter = csv.DictWriter(logfile, fieldnames=['iter', 'acc', 'nmi', 'ari', 'loss'])\n",
    "        logwriter.writeheader()\n",
    "\n",
    "        loss = 0\n",
    "        index = 0\n",
    "        index_array = np.arange(x.shape[0])\n",
    "        for ite in range(int(maxiter)):\n",
    "            if ite % update_interval == 0:\n",
    "                q = self.model.predict(x, verbose=0)\n",
    "                p = self.target_distribution(q)  # update the auxiliary target distribution p\n",
    "\n",
    "                # evaluate the clustering performance\n",
    "                y_pred = q.argmax(1)\n",
    "                if y is not None:\n",
    "                    acc = np.round(accuracy_score(y, y_pred), 5)\n",
    "                    nmi = np.round(normalized_mutual_info_score(y, y_pred), 5)\n",
    "                    ari = np.round(normalized_mutual_info_score(y, y_pred), 5)\n",
    "                    loss = np.round(loss, 5)\n",
    "                    logdict = dict(iter=ite, acc=acc, nmi=nmi, ari=ari, loss=loss)\n",
    "                    logwriter.writerow(logdict)\n",
    "                    print('Iter %d: acc = %.5f, nmi = %.5f, ari = %.5f' % (ite, acc, nmi, ari), ' ; loss=', loss)\n",
    "\n",
    "                # check stop criterion\n",
    "                delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "                y_pred_last = np.copy(y_pred)\n",
    "                if ite > 0 and delta_label < tol:\n",
    "                    print('delta_label ', delta_label, '< tol ', tol)\n",
    "                    print('Reached tolerance threshold. Stopping training.')\n",
    "                    logfile.close()\n",
    "                    break\n",
    "\n",
    "            # train on batch\n",
    "            # if index == 0:\n",
    "            #     np.random.shuffle(index_array)\n",
    "            idx = index_array[index * batch_size: min((index+1) * batch_size, x.shape[0])]\n",
    "            self.model.train_on_batch(x=x[idx], y=p[idx])\n",
    "            index = index + 1 if (index + 1) * batch_size <= x.shape[0] else 0\n",
    "\n",
    "            # save intermediate model\n",
    "            if ite % save_interval == 0:\n",
    "                print('saving model to:', save_dir + '/DEC_model_' + str(ite) + '.h5')\n",
    "                self.model.save_weights(save_dir + '/DEC_model_' + str(ite) + '.h5')\n",
    "\n",
    "            ite += 1\n",
    "\n",
    "        # save the trained model\n",
    "        logfile.close()\n",
    "        print('saving model to:', save_dir + '/DEC_model_final.h5')\n",
    "        self.model.save_weights(save_dir + '/DEC_model_final.h5')\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 13434\n",
      "(1189, 20)\n"
     ]
    }
   ],
   "source": [
    "# setting the hyper parameters\n",
    "init = 'glorot_uniform'\n",
    "pretrain_optimizer = 'adam'\n",
    "dataset = 'mnist'\n",
    "batch_size = 2048\n",
    "maxiter = 2e4\n",
    "tol = 0.001\n",
    "save_dir = 'results'\n",
    "\n",
    "x_data, _ = load_dataset(\"example/IGC.DOI.tsv\")\n",
    "x_data = preprocess_dataset(x_data, padded=not False)\n",
    "train_x = x_data\n",
    "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "#train_x = np.concatenate((x_train, x_test))\n",
    "#train_y = np.concatenate((y_train, y_test))\n",
    "\n",
    "#train_x = train_x.reshape((train_x.shape[0], -1))\n",
    "#train_x = np.divide(train_x, 255.)\n",
    "\n",
    "#split_size = int(train_x.shape[0]*0.85)\n",
    "#train_x, val_x = train_x[:split_size,], train_x[split_size:,]\n",
    "#train_y,val_y = train_y[:split_size], train_y[split_size:]\n",
    "\n",
    "\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "update_interval = 200\n",
    "pretrain_epochs = 100\n",
    "init = VarianceScaling(scale=1. / 3., mode='fan_in',distribution='uniform')  # [-limit, limit], limit=sqrt(1./fan_in)\n",
    "#pretrain_optimizer = SGD(lr=1, momentum=0.9)\n",
    "\n",
    "\n",
    "# prepare the DEC model\n",
    "dec = DEC(dims=[(1189,20),400,800,400,400], n_clusters=12, init=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Pretraining...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected deconv1 to have 4 dimensions, but got array with shape (13434, 1189, 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-bc316de6f11f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m dec.pretrain(x=train_x, optimizer=pretrain_optimizer,\n\u001b[1;32m      2\u001b[0m              \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrain_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m              save_dir=save_dir)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-084340fede0a>\u001b[0m in \u001b[0;36mpretrain\u001b[0;34m(self, x, y, optimizer, epochs, batch_size, save_dir)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;31m# begin pretraining\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pretraining time: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/ae_weights.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/keras/engine/training_utils.pyc\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected deconv1 to have 4 dimensions, but got array with shape (13434, 1189, 20)"
     ]
    }
   ],
   "source": [
    "dec.pretrain(x=train_x, optimizer=pretrain_optimizer,\n",
    "             epochs=pretrain_epochs, batch_size=batch_size,\n",
    "             save_dir=save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "encoder_0 (Dense)            (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "encoder_1 (Dense)            (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "encoder_2 (Dense)            (None, 2000)              1002000   \n",
      "_________________________________________________________________\n",
      "encoder_3 (Dense)            (None, 10)                20010     \n",
      "_________________________________________________________________\n",
      "clustering (ClusteringLayer) (None, 12)                120       \n",
      "=================================================================\n",
      "Total params: 1,665,130\n",
      "Trainable params: 1,665,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dec.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Update interval', 200)\n",
      "('Save interval', 145)\n",
      "Initializing cluster centers with k-means.\n",
      "('Iter 0: acc = 0.10489, nmi = 0.73327, ari = 0.73327', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_0.h5')\n",
      "('saving model to:', 'results/DEC_model_145.h5')\n",
      "('Iter 200: acc = 0.10365, nmi = 0.74296, ari = 0.74296', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_290.h5')\n",
      "('Iter 400: acc = 0.10309, nmi = 0.74699, ari = 0.74699', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_435.h5')\n",
      "('saving model to:', 'results/DEC_model_580.h5')\n",
      "('Iter 600: acc = 0.10250, nmi = 0.75493, ari = 0.75493', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_725.h5')\n",
      "('Iter 800: acc = 0.10166, nmi = 0.76255, ari = 0.76255', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_870.h5')\n",
      "('Iter 1000: acc = 0.10168, nmi = 0.76847, ari = 0.76847', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_1015.h5')\n",
      "('saving model to:', 'results/DEC_model_1160.h5')\n",
      "('Iter 1200: acc = 0.10128, nmi = 0.77385, ari = 0.77385', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_1305.h5')\n",
      "('Iter 1400: acc = 0.10116, nmi = 0.77820, ari = 0.77820', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_1450.h5')\n",
      "('saving model to:', 'results/DEC_model_1595.h5')\n",
      "('Iter 1600: acc = 0.10128, nmi = 0.78223, ari = 0.78223', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_1740.h5')\n",
      "('Iter 1800: acc = 0.10111, nmi = 0.78610, ari = 0.78610', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_1885.h5')\n",
      "('Iter 2000: acc = 0.10092, nmi = 0.78886, ari = 0.78886', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_2030.h5')\n",
      "('saving model to:', 'results/DEC_model_2175.h5')\n",
      "('Iter 2200: acc = 0.10113, nmi = 0.79113, ari = 0.79113', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_2320.h5')\n",
      "('Iter 2400: acc = 0.10104, nmi = 0.79260, ari = 0.79260', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_2465.h5')\n",
      "('Iter 2600: acc = 0.10092, nmi = 0.79417, ari = 0.79417', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_2610.h5')\n",
      "('saving model to:', 'results/DEC_model_2755.h5')\n",
      "('Iter 2800: acc = 0.10109, nmi = 0.79524, ari = 0.79524', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_2900.h5')\n",
      "('Iter 3000: acc = 0.10111, nmi = 0.79632, ari = 0.79632', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_3045.h5')\n",
      "('saving model to:', 'results/DEC_model_3190.h5')\n",
      "('Iter 3200: acc = 0.10108, nmi = 0.79696, ari = 0.79696', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_3335.h5')\n",
      "('Iter 3400: acc = 0.10129, nmi = 0.79786, ari = 0.79786', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_3480.h5')\n",
      "('Iter 3600: acc = 0.10118, nmi = 0.79788, ari = 0.79788', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_3625.h5')\n",
      "('saving model to:', 'results/DEC_model_3770.h5')\n",
      "('Iter 3800: acc = 0.10108, nmi = 0.79842, ari = 0.79842', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_3915.h5')\n",
      "('Iter 4000: acc = 0.10123, nmi = 0.79911, ari = 0.79911', ' ; loss=', 0)\n",
      "('saving model to:', 'results/DEC_model_4060.h5')\n",
      "('Iter 4200: acc = 0.10118, nmi = 0.79931, ari = 0.79931', ' ; loss=', 0)\n",
      "('delta_label ', 0.000957983193277311, '< tol ', 0.001)\n",
      "Reached tolerance threshold. Stopping training.\n",
      "('saving model to:', 'results/DEC_model_final.h5')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.809492606873538"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec.compile(optimizer=SGD(0.01, 0.9), loss='kld')\n",
    "y_pred = dec.fit(train_x,train_y,tol=tol, maxiter=maxiter, batch_size=batch_size,update_interval=update_interval, save_dir=save_dir)\n",
    "pred_val = dec.predict(val_x)\n",
    "normalized_mutual_info_score(val_y, pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6, 7, 8, 9, 5, 6, 6], dtype=uint8)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(val_y, pred_val)\n",
    "(val_y)[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  7,  8,  5,  6,  0,  7,  8,  8])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_val)[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 784)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[:5000,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder(dims, act='relu', init='glorot_uniform'):\n",
    "    \"\"\"\n",
    "    Fully connected auto-encoder model, symmetric.\n",
    "    Arguments:\n",
    "        dims: list of number of units in each layer of encoder. dims[0] is input dim, dims[-1] is units in hidden layer.\n",
    "            The decoder is symmetric with encoder. So number of layers of the auto-encoder is 2*len(dims)-1\n",
    "        act: activation, not applied to Input, Hidden and Output layers\n",
    "    return:\n",
    "        (ae_model, encoder_model), Model of autoencoder and model of encoder\n",
    "    \"\"\"\n",
    "    n_stacks = len(dims) - 1\n",
    "    # input\n",
    "    x = Input(shape=(dims[0],), name='input')\n",
    "    h = x\n",
    "\n",
    "    # internal layers in encoder\n",
    "    for i in range(n_stacks-1):\n",
    "        h = Dense(dims[i + 1], activation=act, kernel_initializer=init, name='encoder_%d' % i)(h)\n",
    "\n",
    "    # hidden layer\n",
    "    h = Dense(dims[-1], kernel_initializer=init, name='encoder_%d' % (n_stacks - 1))(h)  # hidden layer, features are extracted from here\n",
    "\n",
    "    y = h\n",
    "    # internal layers in decoder\n",
    "    for i in range(n_stacks-1, 0, -1):\n",
    "        y = Dense(dims[i], activation=act, kernel_initializer=init, name='decoder_%d' % i)(y)\n",
    "\n",
    "    # output\n",
    "    y = Dense(dims[0], kernel_initializer=init, name='decoder_0')(y)\n",
    "\n",
    "    return Model(inputs=x, outputs=y, name='AE'), Model(inputs=x, outputs=h, name='encoder')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Conv1DTranspose(input_tensor, filters, kernel_size, strides=2, padding='same'):\n",
    "    x = Lambda(lambda x: K.expand_dims(x, axis=2))(input_tensor)\n",
    "    x = Conv2DTranspose(filters=filters, kernel_size=(kernel_size, 1), strides=(strides, 1), padding=padding)(x)\n",
    "    x = Lambda(lambda x: K.squeeze(x, axis=2))(x)\n",
    "    return x\n",
    "\n",
    "def autoencoderConv2D_1(input_shape=(1590, 20), filters=[400,800,400,400]):\n",
    "    \n",
    "    input_seq = Input(shape=input_shape)\n",
    "    \n",
    "    #if input_shape[0] % 8 == 0:\n",
    "    #    pad3 = 'same'\n",
    "    #else:\n",
    "    #    pad3 = 'valid'\n",
    "    \n",
    "    #x = Conv2D(filters[0], 5, strides=2, padding='same', activation='relu', name='conv1', input_shape=input_shape)(input_img)\n",
    "    x = Convolution1D(filters=filters[0],kernel_size=50,strides=1,padding='same',use_bias=False,kernel_initializer='glorot_uniform',activation='relu',name='Conv1')(input_seq)\n",
    "    x = Convolution1D(filters=filters[1],kernel_size=50,strides=1,padding='same',use_bias=False,kernel_initializer='glorot_uniform',activation='relu',name='Conv2')(x)\n",
    "\n",
    "    #x = Conv2D(filters[2], 3, strides=2, padding=pad3, activation='relu', name='conv3')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=filters[2], name='embedding')(x)\n",
    "    encoded = Dense(units=filters[3], name='embedding')(x)\n",
    "    x = Dense(units=filters[3], activation='relu')(encoded)\n",
    "    x = Dense(units=filters[2], activation='relu')(x)\n",
    "    \n",
    "    x = Reshape((1,400))(x)\n",
    "    \n",
    "    x = Reshape((-1,1,20))(x)\n",
    "    \n",
    "    #x = Conv2DTranspose(filters[1], 3, strides=2, padding=pad3, activation='relu', name='deconv3')(x)\n",
    "\n",
    "    x = Conv2DTranspose(filters=20, kernel_size = (50,1),strides=1, padding='same', activation='relu', name='deconv2')(x)\n",
    "\n",
    "    decoded = Conv2DTranspose(input_shape[1], kernel_size = (50,1), strides=1, padding='same', name='deconv1')(x)\n",
    "    \n",
    "    return Model(inputs=input_seq, outputs=decoded, name='AE'), Model(inputs=input_seq, outputs=encoded, name='encoder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters=[32, 64, 128, 10]\n",
    "filters[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(3-1, 0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow1.1_p36]",
   "language": "python",
   "name": "conda-env-tensorflow1.1_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
